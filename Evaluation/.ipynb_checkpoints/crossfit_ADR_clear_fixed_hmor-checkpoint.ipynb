{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dac573f9-813c-479a-adf9-6922855cb4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing .feather files into a list of DFs in Python\n",
    "from cmath import nan\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "import random\n",
    "import feather\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pickle\n",
    "from speedboot import speedboot\n",
    "\n",
    "os.chdir(\"/Users/francois/Desktop/github repos/MIMIC-DTR/validation/feather_files_hmor\")\n",
    "directory = \"/Users/francois/Desktop/github repos/MIMIC-DTR/validation/feather_files_hmor\"\n",
    "\n",
    "list_of_DFs = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    DF = feather.read_dataframe(filename)\n",
    "    DF = DF[~DF.orig_id.duplicated()]\n",
    "    list_of_DFs.append(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22acc59d-63e7-49f1-83fc-65ccf6cbb8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tau_pi_fun(xs):\n",
    "    i = 1\n",
    "    for x in xs:\n",
    "        if x is True:\n",
    "            break\n",
    "        else:\n",
    "            i += 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6654dae3-09ee-4846-8c34-564024437604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bool_rec_fun(df):\n",
    "    \"\"\"Get policies 'stoping times' tau_\\pi \"\"\"\n",
    "    bool_rec = df[[\"r_1\", \"r_2\", \"r_3\"]] == 1\n",
    "    df['tau_pi'] = bool_rec.apply(tau_pi_fun, axis=1)\n",
    "    bool_clin = df[[\"a1\", \"a2\", \"a3\"]] == 1\n",
    "    df['tau_clin'] = bool_clin.apply(tau_pi_fun, axis=1)\n",
    "    bool_rec_s = df[[\"r_s_1\", \"r_s_2\", \"r_s_3\"]] == 1\n",
    "    df['tau_pi_s'] = bool_rec_s.apply(tau_pi_fun, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c83e5b-9c7b-4543-81ee-820656f7f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_ttt_reco_in_death(df):\n",
    "    df.loc[df[\"phi_2\"]==1, \"a2\"] = 0\n",
    "    df.loc[df[\"phi_3\"]==1, \"a3\"] = 0\n",
    "\n",
    "    df.loc[df[\"phi_2\"]==1, \"r_2\"] = 0\n",
    "    df.loc[df[\"phi_3\"]==1, \"r_3\"] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74b2d27-ad9c-492d-8a7f-d160dbfcee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_imp_dfs = [bool_rec_fun(imp_i) for imp_i in list_of_DFs]\n",
    "prep_imp_dfs = [fill_ttt_reco_in_death(imp_i) for imp_i in prep_imp_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc82da5-0ec0-4cf2-9e79-8e1f01c71a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitmodels(imp_1):\n",
    "    \"\"\"Fit the 4 x 3 -1 models needed in algorithm 2 ADR estimator with terminal state\"\"\"\n",
    "    ### e_s\n",
    "\n",
    "    e_1 = LogisticRegression(max_iter=2000, solver='lbfgs', penalty='none') #2\n",
    "    e_2 = LogisticRegression(max_iter=2000, solver='lbfgs', penalty='none') #.5\n",
    "    e_3 = LogisticRegression(max_iter=2000, solver='lbfgs', C=.5) #.2\n",
    "\n",
    "    cond_e_1 = pd.Series([True] * len(imp_1))\n",
    "    cond_e_2 = (imp_1[\"a1\"] == 0) & (imp_1[\"phi_1\"] == 0) \n",
    "    cond_e_3 = (imp_1[\"a2\"] == 0) & (imp_1[\"phi_2\"] == 0) \n",
    "    \n",
    "    baseline = [\"admission_age\", \"gender\", \"weight\", \"immunosuppressant\", \"SOFA_24hours\"]\n",
    "    \n",
    "    e_var_1 = [\"bun_k1\", \"uo_k1\", \"pot_k1\", \"ph_k1\"]\n",
    "    e_var_2 = [\"bun_k2\", \"uo_k2\", \"pot_k2\", \"ph_k2\"]  \n",
    "    e_var_3 = [\"bun_k3\", \"uo_k3\", \"pot_k3\", \"ph_k3\"]\n",
    "    \n",
    "    #e_var_1 = [\"bun_k1\", \"pot_k1\", \"ph_k1\"]#[\"bun_k1\", \"uo_k1\", \"pot_k1\", \"ph_k1\"]\n",
    "    #e_var_2 = [\"bun_k2\", \"uo_k2\", \"pot_k2\", \"ph_k2\"]  \n",
    "    #e_var_3 = [\"bun_k3\", \"uo_k3\", \"pot_k3\", \"ph_k3\"]\n",
    "    \n",
    "    #e_var_1 = baseline + [\"bun_k1\", \"uo_k1\", \"pot_k1\", \"ph_k1\"]\n",
    "    #e_var_2 = baseline + [\"bun_k2\", \"uo_k2\", \"pot_k2\", \"ph_k2\"]  \n",
    "    #e_var_3 = baseline + [\"bun_k3\", \"uo_k3\", \"pot_k3\", \"ph_k3\"]\n",
    "\n",
    "    X_e_1 = imp_1[e_var_1]\n",
    "    X_e_2 = imp_1[cond_e_2][e_var_2]\n",
    "    X_e_3 = imp_1[cond_e_3][e_var_3]\n",
    "\n",
    "    Y_e_1 = imp_1[\"a1\"]\n",
    "    Y_e_2 = imp_1[cond_e_2][\"a2\"]\n",
    "    Y_e_3 = imp_1[cond_e_3][\"a3\"]\n",
    "\n",
    "    e_1.fit(X_e_1, Y_e_1)\n",
    "    e_2.fit(X_e_2, Y_e_2)\n",
    "    e_3.fit(X_e_3, Y_e_3)\n",
    "\n",
    "    #preds_e_1 = e_1.predict_proba(imp_1[e_var_1])[:,1]\n",
    "    preds_e_2 = e_2.predict_proba(imp_1[e_var_2])[:,1]\n",
    "    preds_e_3 = e_3.predict_proba(imp_1[e_var_3])[:,1]\n",
    "\n",
    "    ### mu_nows\n",
    "\n",
    "    mu_now_1 = LogisticRegression(max_iter=20000, solver='lbfgs')#RandomForestClassifier(random_state=0)\n",
    "    mu_now_2 = LogisticRegression(max_iter=20000, solver='lbfgs')#RandomForestClassifier(random_state=0)\n",
    "    mu_now_3 = LogisticRegression(max_iter=20000, solver='lbfgs')#RandomForestClassifier(random_state=0)\n",
    "\n",
    "    cond_mu_now_1 = imp_1[\"a1\"] == 1\n",
    "    cond_mu_now_2 = (imp_1[\"a1\"] == 0) & (imp_1[\"a2\"] == 1) & (imp_1[\"phi_2\"] == 0) \n",
    "    cond_mu_now_3 = (imp_1[\"a2\"] == 0) & (imp_1[\"a3\"] == 1) & (imp_1[\"phi_3\"] == 0) \n",
    "\n",
    "    mu_var_1 = [\"admission_age\", \"gender\", \"weight\", \"immunosuppressant\", \"SOFA_24hours\", \"creat_k1\", \"bun_k1\", \"pot_k1\", \"ph_k1\", \"uo_k1\"]\n",
    "    #mu_var_2 = [\"admission_age\"]#[\"creat_k2\", \"bun_k2\", \"pot_k2\", \"ph_k2\", \"uo_k2\"]\n",
    "    #mu_var_3 = [\"admission_age\"]#[\"creat_k3\", \"bun_k3\", \"pot_k3\", \"ph_k3\", \"uo_k3\"]\n",
    "    mu_var_2 = mu_var_1 + [\"creat_k2\", \"bun_k2\", \"pot_k2\", \"ph_k2\", \"uo_k2\"]\n",
    "    mu_var_3 = mu_var_2 + [\"creat_k3\", \"bun_k3\", \"pot_k3\", \"ph_k3\", \"uo_k3\"]\n",
    "    \n",
    "    #mu_var_1 = [\"admission_age\", \"gender\", \"weight\", \"SOFA_24hours\", \"creat_k1\", \"pot_k1\", \"uo_k1\"]#[\"admission_age\", \"gender\", \"weight\", \"immunosuppressant\", \"SOFA_24hours\", \"creat_k1\", \"bun_k1\", \"pot_k1\", \"ph_k1\", \"uo_k1\"]\n",
    "    #mu_var_2 = mu_var_1 + [\"bun_k2\", \"ph_k1\", \"ph_k2\", \"uo_k1\", \"uo_k2\"]\n",
    "    #mu_var_3 = mu_var_1 + [\"bun_k1\", \"bun_k3\", \"uo_k3\"]\n",
    "\n",
    "    X_mu_now_1 = imp_1[cond_mu_now_1][mu_var_1]\n",
    "    X_mu_now_2 = imp_1[cond_mu_now_2][mu_var_2]\n",
    "    X_mu_now_3 = imp_1[cond_mu_now_3][mu_var_3]\n",
    "\n",
    "    Y_mu_now_1 = imp_1[cond_mu_now_1][\"hmor\"]\n",
    "    Y_mu_now_2 = imp_1[cond_mu_now_2][\"hmor\"]\n",
    "    Y_mu_now_3 = imp_1[cond_mu_now_3][\"hmor\"]\n",
    "\n",
    "    mu_now_1.fit(X_mu_now_1, Y_mu_now_1)\n",
    "    mu_now_2.fit(X_mu_now_2, Y_mu_now_2)\n",
    "    mu_now_3.fit(X_mu_now_3, Y_mu_now_3)\n",
    "\n",
    "    #preds_mu_now_1 = mu_now_1.predict(imp_1[mu_var_1]) \n",
    "    #preds_mu_now_2 = mu_now_2.predict(imp_1[mu_var_2]) \n",
    "    #preds_mu_now_3 = mu_now_3.predict(imp_1[mu_var_3]) \n",
    "\n",
    "    ### U_nexts\n",
    "\n",
    "    U_next_1 = LogisticRegression(max_iter=20000, solver='lbfgs')#RandomForestClassifier(random_state=0)\n",
    "    U_next_2 = LogisticRegression(max_iter=20000, solver='lbfgs')#RandomForestClassifier(random_state=0)\n",
    "    U_next_3 = LogisticRegression(max_iter=20000, solver='lbfgs')#RandomForestClassifier(random_state=0)\n",
    "\n",
    "    cond_U_next_1 = (imp_1[\"a1\"] == 0) & (imp_1[\"a2\"] == 1) & (imp_1[\"phi_2\"] == 0)\n",
    "    cond_U_next_2 = (imp_1[\"a2\"] == 0) & (imp_1[\"a3\"] == 1) & (imp_1[\"phi_2\"] == 0) & (imp_1[\"phi_3\"] == 0)\n",
    "    cond_U_next_3 = (imp_1[\"a3\"] == 0) & (imp_1[\"phi_3\"] == 0)\n",
    "\n",
    "    X_U_next_1 = imp_1[cond_U_next_1][mu_var_1]\n",
    "    X_U_next_2 = imp_1[cond_U_next_2][mu_var_2]\n",
    "    X_U_next_3 = imp_1[cond_U_next_3][mu_var_3]\n",
    "\n",
    "    Y_U_next_1 = imp_1[cond_U_next_1][\"hmor\"] \n",
    "    Y_U_next_2 = imp_1[cond_U_next_2][\"hmor\"] \n",
    "    Y_U_next_3 = imp_1[cond_U_next_3][\"hmor\"]\n",
    "\n",
    "    U_next_1.fit(X_U_next_1, Y_U_next_1, sample_weight=(1/preds_e_2)[cond_U_next_1])\n",
    "    U_next_2.fit(X_U_next_2, Y_U_next_2, sample_weight=(1/preds_e_3)[cond_U_next_2])\n",
    "    U_next_3.fit(X_U_next_3, Y_U_next_3)\n",
    "\n",
    "    #preds_U_next_1 = U_next_1.predict(imp_1[mu_var_1])\n",
    "    #preds_U_next_2 = U_next_2.predict(imp_1[mu_var_2])\n",
    "    #preds_U_next_3 = U_next_3.predict(imp_1[mu_var_3])\n",
    "\n",
    "    ### rhos\n",
    "\n",
    "    rho_1 = RandomForestClassifier(random_state=0)\n",
    "    rho_2 = RandomForestClassifier(random_state=0)\n",
    "    # rho_3 is not needed\n",
    "\n",
    "    cond_rho_1 = (imp_1[\"a1\"] == 0)\n",
    "    cond_rho_2 = (imp_1[\"a2\"] == 0) & (imp_1[\"phi_2\"] == 0)\n",
    "    # rho_3 is not needed\n",
    "\n",
    "    X_rho_1 = imp_1[cond_rho_1][mu_var_1]\n",
    "    X_rho_2 = imp_1[cond_rho_2][mu_var_2]\n",
    "\n",
    "    Y_rho_1 = imp_1[cond_rho_1][\"phi_2\"]\n",
    "    Y_rho_2 = imp_1[cond_rho_2][\"phi_3\"]\n",
    "\n",
    "    rho_1.fit(X_rho_1, Y_rho_1)\n",
    "    rho_2.fit(X_rho_2, Y_rho_2)\n",
    "\n",
    "    #preds_rho_1 = rho_1.predict_proba(imp_1[mu_var_1])[:,1]\n",
    "    #preds_rho_2 = rho_2.predict_proba(imp_1[mu_var_2])[:,1]\n",
    "\n",
    "    ## return models\n",
    "    return e_1, e_2, e_3, mu_now_1, mu_now_2, mu_now_3, U_next_1, U_next_2, U_next_3, rho_1, rho_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67503051-2cd7-4c53-9b4f-7c796eece145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossfitted_preds(fold, e_1, e_2, e_3, mu_now_1, mu_now_2, mu_now_3, U_next_1, U_next_2, U_next_3, rho_1, rho_2):\n",
    "    \"\"\"returns crossfitted predictions from previously fitted models\"\"\"\n",
    "    \n",
    "    baseline = [\"admission_age\", \"gender\", \"weight\", \"immunosuppressant\", \"SOFA_24hours\"]\n",
    "    \n",
    "    e_var_1 = [\"bun_k1\", \"uo_k1\", \"pot_k1\", \"ph_k1\"]\n",
    "    e_var_2 = [\"bun_k2\", \"uo_k2\", \"pot_k2\", \"ph_k2\"]  \n",
    "    e_var_3 = [\"bun_k3\", \"uo_k3\", \"pot_k3\", \"ph_k3\"]\n",
    "    \n",
    "    #e_var_1 = [\"bun_k1\", \"pot_k1\", \"ph_k1\"]#[\"bun_k1\", \"uo_k1\", \"pot_k1\", \"ph_k1\"]\n",
    "    #e_var_2 = [\"bun_k2\", \"uo_k2\", \"pot_k2\", \"ph_k2\"]  \n",
    "    #e_var_3 = [\"bun_k3\", \"uo_k3\", \"pot_k3\", \"ph_k3\"]\n",
    "    \n",
    "    #e_var_1 = baseline + [\"bun_k1\", \"uo_k1\", \"pot_k1\", \"ph_k1\"]\n",
    "    #e_var_2 = baseline + [\"bun_k2\", \"uo_k2\", \"pot_k2\", \"ph_k2\"]  \n",
    "    #e_var_3 = baseline + [\"bun_k3\", \"uo_k3\", \"pot_k3\", \"ph_k3\"]\n",
    "    \n",
    "    mu_var_1 = [\"admission_age\", \"gender\", \"weight\", \"immunosuppressant\", \"SOFA_24hours\", \"creat_k1\", \"bun_k1\", \"pot_k1\", \"ph_k1\", \"uo_k1\"]\n",
    "    mu_var_2 = mu_var_1 + [\"creat_k2\", \"bun_k2\", \"pot_k2\", \"ph_k2\", \"uo_k2\"]\n",
    "    mu_var_3 = mu_var_2 + [\"creat_k3\", \"bun_k3\", \"pot_k3\", \"ph_k3\", \"uo_k3\"]\n",
    "    #mu_var_2 = [\"admission_age\"]#[\"creat_k2\", \"bun_k2\", \"pot_k2\", \"ph_k2\", \"uo_k2\"]\n",
    "    #mu_var_3 = [\"admission_age\"]#[\"creat_k3\", \"bun_k3\", \"pot_k3\", \"ph_k3\", \"uo_k3\"]\n",
    "    \n",
    "    #mu_var_1 = [\"admission_age\", \"gender\", \"weight\", \"SOFA_24hours\", \"creat_k1\", \"pot_k1\", \"uo_k1\"]#[\"admission_age\", \"gender\", \"weight\", \"immunosuppressant\", \"SOFA_24hours\", \"creat_k1\", \"bun_k1\", \"pot_k1\", \"ph_k1\", \"uo_k1\"]\n",
    "    #mu_var_2 = mu_var_1 + [\"bun_k2\", \"ph_k1\", \"ph_k2\", \"uo_k1\", \"uo_k2\"]\n",
    "    #mu_var_3 = mu_var_1 + [\"bun_k1\", \"bun_k3\", \"uo_k3\"]\n",
    "    \n",
    "    ### e_s\n",
    "\n",
    "    preds_e_1 = e_1.predict_proba(fold[e_var_1])[:,1]\n",
    "    preds_e_2 = e_2.predict_proba(fold[e_var_2])[:,1]\n",
    "    preds_e_3 = e_3.predict_proba(fold[e_var_3])[:,1]\n",
    "\n",
    "    ### mu_nows\n",
    "\n",
    "    preds_mu_now_1 = mu_now_1.predict(fold[mu_var_1]) \n",
    "    preds_mu_now_2 = mu_now_2.predict(fold[mu_var_2]) \n",
    "    preds_mu_now_3 = mu_now_3.predict(fold[mu_var_3]) \n",
    "\n",
    "    ### U_nexts\n",
    "\n",
    "    preds_U_next_1 = U_next_1.predict(fold[mu_var_1])\n",
    "    preds_U_next_2 = U_next_2.predict(fold[mu_var_2])\n",
    "    preds_U_next_3 = U_next_3.predict(fold[mu_var_3])\n",
    "\n",
    "    ### rhos\n",
    "\n",
    "    preds_rho_1 = rho_1.predict_proba(fold[mu_var_1])[:,1]\n",
    "    preds_rho_2 = rho_2.predict_proba(fold[mu_var_2])[:,1]\n",
    "\n",
    "    ## return models\n",
    "    return preds_e_1, preds_e_2, preds_e_3, preds_mu_now_1, preds_mu_now_2, preds_mu_now_3, preds_U_next_1, preds_U_next_2, preds_U_next_3, preds_rho_1, preds_rho_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b660add-b481-4633-8e95-70c80562416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conc_cf_preds(fold_1, fold_2):\n",
    "    \"\"\"concatenates crossfitted predictions given two folds\"\"\"\n",
    "    \n",
    "    #(e_1, e_2, e_3, preds_e_2, preds_e_3) = fit_e_s(fold_1)\n",
    "    (e_1, e_2, e_3, mu_now_1, mu_now_2, mu_now_3, U_next_1, U_next_2, U_next_3, rho_1, rho_2) = fitmodels(fold_2)#, e_2, e_3)\n",
    "    f_1_preds_e_1, f_1_preds_e_2, f_1_preds_e_3, f_1_preds_mu_now_1, f_1_preds_mu_now_2, f_1_preds_mu_now_3, f_1_preds_U_next_1, f_1_preds_U_next_2, f_1_preds_U_next_3, f_1_preds_rho_1, f_1_preds_rho_2 = crossfitted_preds(fold_1, e_1, e_2, e_3, mu_now_1, mu_now_2, mu_now_3, U_next_1, U_next_2, U_next_3, rho_1, rho_2)\n",
    "\n",
    "    #(e_1, e_2, e_3, preds_e_2, preds_e_3) = fit_e_s(fold_2)\n",
    "    (e_1, e_2, e_3, mu_now_1, mu_now_2, mu_now_3, U_next_1, U_next_2, U_next_3, rho_1, rho_2) = fitmodels(fold_1)#, e_2, e_3)\n",
    "    f_2_preds_e_1, f_2_preds_e_2, f_2_preds_e_3, f_2_preds_mu_now_1, f_2_preds_mu_now_2, f_2_preds_mu_now_3, f_2_preds_U_next_1, f_2_preds_U_next_2, f_2_preds_U_next_3, f_2_preds_rho_1, f_2_preds_rho_2 = crossfitted_preds(fold_2, e_1, e_2, e_3, mu_now_1, mu_now_2, mu_now_3, U_next_1, U_next_2, U_next_3, rho_1, rho_2)\n",
    "    \n",
    "    preds_e_1 = np.concatenate((f_1_preds_e_1, f_2_preds_e_1))\n",
    "    preds_e_2 = np.concatenate((f_1_preds_e_2, f_2_preds_e_2))\n",
    "    preds_e_3 = np.concatenate((f_1_preds_e_3, f_2_preds_e_3))\n",
    "    \n",
    "    preds_mu_now_1 = np.concatenate((f_1_preds_mu_now_1, f_2_preds_mu_now_1))\n",
    "    preds_mu_now_2 = np.concatenate((f_1_preds_mu_now_2, f_2_preds_mu_now_2))\n",
    "    preds_mu_now_3 = np.concatenate((f_1_preds_mu_now_3, f_2_preds_mu_now_3))\n",
    "    \n",
    "    preds_U_next_1 = np.concatenate((f_1_preds_U_next_1, f_2_preds_U_next_1))\n",
    "    preds_U_next_2 = np.concatenate((f_1_preds_U_next_2, f_2_preds_U_next_2))\n",
    "    preds_U_next_3 = np.concatenate((f_1_preds_U_next_3, f_2_preds_U_next_3))\n",
    "    \n",
    "    preds_rho_1 = np.concatenate((f_1_preds_rho_1, f_2_preds_rho_1))\n",
    "    preds_rho_2 = np.concatenate((f_1_preds_rho_2, f_2_preds_rho_2))\n",
    "    \n",
    "    return preds_e_1, preds_e_2, preds_e_3, preds_mu_now_1, preds_mu_now_2, preds_mu_now_3, preds_U_next_1, preds_U_next_2, preds_U_next_3, preds_rho_1, preds_rho_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dea70b9e-a3ba-4b27-978b-f0cad43358ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf_ADR(data, verbose=False):\n",
    "    \"\"\"computes two folds crossfitted ADR estimator given data\"\"\"\n",
    "    \n",
    "    # shuffle the data in-place\n",
    "    data = data.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "    # get index for a two fold cut\n",
    "    cut_i = int(len(data)/2)\n",
    "\n",
    "    # cut data in two folds\n",
    "    fold_1 = data.iloc[0:cut_i]\n",
    "    fold_2 = data.iloc[cut_i:]\n",
    "    \n",
    "    preds_e_1, preds_e_2, preds_e_3, preds_mu_now_1, preds_mu_now_2, preds_mu_now_3, preds_U_next_1, preds_U_next_2, preds_U_next_3, preds_rho_1, preds_rho_2 = conc_cf_preds(fold_1, fold_2)\n",
    "\n",
    "    ### mu_nexts\n",
    "\n",
    "    preds_mu_next_1 = (1-preds_rho_1) * preds_U_next_1\n",
    "    preds_mu_next_2 = (1-preds_rho_2) * preds_U_next_2\n",
    "    preds_mu_next_3 = preds_U_next_3\n",
    "\n",
    "    ### DR scores\n",
    "\n",
    "    dr_1 = (preds_mu_now_1 - preds_mu_next_1) + (data[\"a1\"]==1).astype(int) * (data[\"hmor\"] - preds_mu_now_1)/preds_e_1 - (data[\"a1\"]==0).astype(int) * (data[\"a2\"]==1).astype(int) * (data[\"hmor\"] - preds_U_next_1) / ( (1-preds_e_1) * preds_e_2)\n",
    "    dr_2 = (preds_mu_now_2 - preds_mu_next_2) + (data[\"a2\"]==1).astype(int) * (data[\"hmor\"] - preds_mu_now_2)/preds_e_2 - (data[\"a2\"]==0).astype(int) * (data[\"a3\"]==1).astype(int) * (data[\"hmor\"] - preds_U_next_2) / ( (1-preds_e_2) * preds_e_3)\n",
    "    dr_3 = (preds_mu_now_3 - preds_mu_next_3) + (data[\"a3\"]==1).astype(int) * (data[\"hmor\"] - preds_mu_now_3)/preds_e_3 - (data[\"a3\"]==0).astype(int) * (data[\"hmor\"] - preds_U_next_3) / (1-preds_e_3)\n",
    "\n",
    "    ### ADR\n",
    "\n",
    "    # learned policy\n",
    "    adr_t1 = (data[\"phi_1\"]==0).astype(int) * (1 >= data[\"tau_pi\"]).astype(int) * 1 * dr_1 / (1)\n",
    "    adr_t2 = (data[\"phi_2\"]==0).astype(int) * (2 >= data[\"tau_pi\"]).astype(int) * (data[\"a1\"] == 0).astype(int) * dr_2 / (1-preds_e_1)\n",
    "    adr_t3 = (data[\"phi_3\"]==0).astype(int) * (3 >= data[\"tau_pi\"]).astype(int) * (data[\"a2\"] == 0).astype(int) * dr_3 / ((1-preds_e_1) * (1-preds_e_2))\n",
    "\n",
    "    test = (adr_t1 + adr_t2 + adr_t3)\n",
    "    val_learned = np.mean(test)\n",
    "    #test.describe()\n",
    "\n",
    "    # learned stringent policy\n",
    "    adr_t1 = (data[\"phi_1\"]==0).astype(int) * (1 >= data[\"tau_pi_s\"]).astype(int) * 1 * dr_1 / (1)\n",
    "    adr_t2 = (data[\"phi_2\"]==0).astype(int) * (2 >= data[\"tau_pi_s\"]).astype(int) * (data[\"a1\"] == 0).astype(int) * dr_2 / (1-preds_e_1)\n",
    "    adr_t3 = (data[\"phi_3\"]==0).astype(int) * (3 >= data[\"tau_pi_s\"]).astype(int) * (data[\"a2\"] == 0).astype(int) * dr_3 / ((1-preds_e_1) * (1-preds_e_2))\n",
    "\n",
    "    test = (adr_t1 + adr_t2 + adr_t3)\n",
    "    val_learned_s = np.mean(test)\n",
    "    #test.describe()\n",
    "\n",
    "    # clinicians policy\n",
    "    adr_t1 = (data[\"phi_1\"]==0).astype(int) * (1 >= data[\"tau_clin\"]).astype(int) * 1 * dr_1 / (1)\n",
    "    adr_t2 = (data[\"phi_2\"]==0).astype(int) * (2 >= data[\"tau_clin\"]).astype(int) * (data[\"a1\"] == 0).astype(int) * dr_2 / (1-preds_e_1)\n",
    "    adr_t3 = (data[\"phi_3\"]==0).astype(int) * (3 >= data[\"tau_clin\"]).astype(int) * (data[\"a2\"] == 0).astype(int) * dr_3 / ((1-preds_e_1) * (1-preds_e_2))\n",
    "\n",
    "    test = (adr_t1 + adr_t2 + adr_t3)\n",
    "    val_clin = np.mean(test)\n",
    "    #test.describe()\n",
    "\n",
    "    # treat at a1 policy\n",
    "    adr_t1 = (data[\"phi_1\"]==0).astype(int) * 1 * 1 * dr_1 / (1)\n",
    "    adr_t2 = (data[\"phi_2\"]==0).astype(int) * 1 * (data[\"a1\"] == 0).astype(int) * dr_2 / (1-preds_e_1)\n",
    "    adr_t3 = (data[\"phi_3\"]==0).astype(int) * 1 * (data[\"a2\"] == 0).astype(int) * dr_3 / ((1-preds_e_1) * (1-preds_e_2))\n",
    "\n",
    "    test = (adr_t1 + adr_t2 + adr_t3)\n",
    "    val_treat_all = np.mean(test)\n",
    "    #test.describe()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'val_learned = {val_learned:.3f}')\n",
    "        print(f'val_learned stringent = {val_learned_s:.3f}')\n",
    "        print(f'val_clin = {val_clin:.3f}')\n",
    "        print(f'val_treat_all = {val_treat_all:.3f}\\n')\n",
    "\n",
    "    return (val_learned, val_learned_s, val_clin, val_treat_all,  # ref treat none policy 0:4\n",
    "            val_learned-val_clin, val_learned_s-val_clin, val_treat_all-val_clin, # ref clinician policy 4:7\n",
    "            val_learned-val_treat_all, val_learned_s-val_treat_all, # ref treat all policy 7:9\n",
    "            val_learned_s-val_learned # ref learned policy 9\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dc5e431-ac14-415a-8147-c962b24fcb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_comp = [\"learned_v_none\", \"learned_stringent_v_none\", \"clin_v_none\", \"treat_all_v_none\", \n",
    "\"learned_v_clin\", \"learned_stringent_v_clin\", \"treat_all_v_clin\",\n",
    "\"learned_v_treat_all\", \"learned_stringent_v_treat_all\",\n",
    "\"learned_stringent_v_learned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72cf272c-4b7b-4755-a438-a9ff15b4200a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossfit\n",
      "val_learned = 0.084\n",
      "val_learned stringent = -0.004\n",
      "val_clin = -0.270\n",
      "val_treat_all = -0.032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imp_1 = list_of_DFs[0]\n",
    "print('Crossfit')\n",
    "res = cf_ADR(imp_1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bdad375-a51c-4256-a909-aff2abaabac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03114311, -0.00901059, -0.42179092, -0.18398434,  0.39064782,\n",
       "        0.41278033,  0.23780658,  0.15284123,  0.17497375,  0.02213252])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bootrap the whole procedure as presented in the flowchart\n",
    "def procedure_cf(dat):\n",
    "    df = dat.copy()\n",
    "    df = df.append(df[df[\"brasrando\"]=='standard'])\n",
    "    return np.array(cf_ADR(df))\n",
    "\n",
    "procedure_cf(prep_imp_dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d740715f-b771-489e-8f31-595376f034ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 701.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1455.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1141.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1602.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 801.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 978.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1381.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1179.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 642.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1343.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2137.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1409.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 755.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1418.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 644.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 954.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 707.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 971.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 727.93it/s]\n"
     ]
    }
   ],
   "source": [
    "#Bootstrap all datasets\n",
    "def runboot(df):\n",
    "    sb_obj = speedboot(data=df, stats_fun=procedure_cf)\n",
    "    sb_obj.fit(R=1, bar=True, par=True, seed=123)\n",
    "    sb_obj.per = sb_obj.per_ci()\n",
    "    sb_obj.emp = sb_obj.emp_ci()\n",
    "    \n",
    "    #sb_obj.jackknife(bar=True, par=True)\n",
    "    #sb_obj.bca = sb_obj.bca_ci()\n",
    "    return sb_obj\n",
    "\n",
    "sb_cf_alldf = [runboot(prep_imp_dfs[i]) for i in range(len(prep_imp_dfs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7422eafb-8d07-412e-aa60-bf6da199aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/francois/Desktop/github repos/MIMIC-DTR/validation/python/Terminal state fix/hmor\")\n",
    "with open('sb_cf_alldf.pickle', 'wb') as handle:\n",
    "    pickle.dump(sb_cf_alldf, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8080db1-f455-4e23-84d8-dad002de4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_strat = np.array(['Learned strategy', 'Never treat within 72 hours', 'Treat all within 24 hours'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb092f0a-877c-43d2-805f-b5782fe690e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46433703, 0.46936127, 0.25173017])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_alldf = np.mean(np.array([sb_cf_alldf[i].ests for i in range(len(sb_cf_alldf))]), axis=0)\n",
    "final_pe = np.array([est_alldf[4], -est_alldf[2], est_alldf[6]])\n",
    "final_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94fdc456-0d30-49ac-b99c-e8cd095402d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75551998, 0.75551998],\n",
       "       [0.14903765, 0.14903765],\n",
       "       [0.58650058, 0.58650058]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_alldf = np.mean(np.array([sb_cf_alldf[i].emp for i in range(len(sb_cf_alldf))]), axis=0)\n",
    "final_cis = np.vstack([emp_alldf[4], emp_alldf[2]-2*est_alldf[2], emp_alldf[6]])\n",
    "final_cis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43198430-1e46-4cdd-8868-fc8cdb2798ea",
   "metadata": {},
   "source": [
    "np.save('est_alldf.npy', est_alldf)\n",
    "#np.save('per_alldf.npy', per_alldf)\n",
    "np.save('emp_alldf.npy', emp_alldf)\n",
    "#np.save('bca_alldf.npy', bca_alldf)\n",
    "#np.save('pol_comp.npy', pol_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ebe265-3452-444c-94d6-b0352669f31c",
   "metadata": {},
   "source": [
    "np.save('final_strat.npy', final_strat)\n",
    "np.save('final_pe.npy', final_pe)\n",
    "np.save('final_cis.npy', final_cis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "641fff74-7284-4120-9c28-d7bd570f9f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pb = np.abs([sb_cf_alldf[i].emp for i in range(len(sb_cf_alldf))]) > 1000\n",
    "no_pb = [~np.any(i) for i in is_pb]\n",
    "sum(no_pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d861fd69-aa4e-4259-a93e-09669985bec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91533703 0.91306763 0.70273017]\n",
      "versus .451 under usual care\n"
     ]
    }
   ],
   "source": [
    "est_no_pb_df = np.mean(np.array([sb_cf_alldf[i].ests for i in range(len(sb_cf_alldf))])[no_pb][:,[4,5,6]], axis=0)\n",
    "print(est_no_pb_df + .451)\n",
    "print(f\"versus .451 under usual care\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
